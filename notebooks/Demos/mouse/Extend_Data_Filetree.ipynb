{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this notebooks shows how to covnvert a normal static .h5 file into a filetree dataset and add information to it such as cell positions, match IDs, and so forth. This data preparation is needed whenever the gaussian readout with cortex corrdinates is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datajoint as dj\n",
    "\n",
    "#import dataport\n",
    "#from dataport.bcm import experiment, xmatch, stack\n",
    "from neuralpredictors.data.datasets import FileTreeDataset\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = dj.create_virtual_module('experiment', 'sinzlab_houston_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.Scan()&\"animal_id=22564\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example multiple restriction\n",
    "restriction = [dict(animal_id=23555, session=22, scan_idx=3),  \n",
    "               dict(animal_id=23555, session=23, scan_idx=1), \n",
    "               dict(animal_id=23555, session=18, scan_idx=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this example, only a single dataset is converted\n",
    "restriction = dict(animal_id=22564, session=3, scan_idx=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# experiment.Scan() & restriction\n",
    "template = '/data/mouse/toliaslab/static/static{animal_id}-{session}-{scan_idx}-preproc0'\n",
    "datasets = [(template + '.h5').format(**k) \n",
    "                for k in (experiment.Scan() & restriction).fetch('KEY')]\n",
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for datafile in datasets:\n",
    "    with h5py.File(datafile) as fid:\n",
    "        print(datafile, fid['images'].shape)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for datapath in Path('data/').glob('*.h5'):\n",
    "#     FileTreeDataset.initialize_from(datapath)\n",
    "\n",
    "for datafile in datasets:\n",
    "    FileTreeDataset.initialize_from(datafile,include_behavior=True, overwrite=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zip data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in (experiment.Scan() & restriction).proj():\n",
    "    filename = (template + '/').format(**key)\n",
    "    dat = FileTreeDataset(filename, 'images', 'responses')\n",
    "    dat.zip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link inputs and targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in (experiment.Scan() & restriction).fetch('KEY'):\n",
    "    filename = (template + '/').format(**key)\n",
    "    print(filename)\n",
    "    dat = FileTreeDataset(filename, 'images', 'responses')\n",
    "    dat.add_link('responses', 'targets')\n",
    "    dat.add_link('images', 'inputs')\n",
    "    print(dat)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augment with Cell positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in (experiment.Scan() & restriction).fetch('KEY'):\n",
    "    print(key)\n",
    "    filename = (template + '/').format(**key)\n",
    "    dat = FileTreeDataset(filename, 'images', 'responses')\n",
    "    ai, se, si, ui, x, y, z = (experiment.ScanSet.UnitInfo & key).fetch('animal_id', 'session', 'scan_idx', 'unit_id', 'um_x', 'um_y', 'um_z')\n",
    "    p = np.c_[x,y,z]\n",
    "    dat.add_neuron_meta('cell_motor_coordinates', ai, se, si, ui, p)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.neurons.cell_motor_coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augment with cell matching from StackSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in (experiment.Scan() & restriction).proj():\n",
    "    filename = (template + '/').format(**key)\n",
    "    dat = FileTreeDataset(filename, 'images', 'responses')\n",
    "    \n",
    "    key['scan_session'] = key.pop('session')\n",
    "    rel = experiment.StackSet.Match() * experiment.StackSet.Unit() & key\n",
    "    ai, se, si, ui, match_id, mx, my, mz = rel.fetch('animal_id', 'scan_session', 'scan_idx', 'unit_id', \n",
    "                                                     'munit_id','munit_x','munit_y','munit_z')\n",
    "    dat.add_neuron_meta('multi_match_id', ai, se, si, ui, match_id, fill_missing=-1)\n",
    "    \n",
    "    munit_coordinates = np.c_[mx, my, mz]\n",
    "    dat.add_neuron_meta('multi_unit_stack_coordinates', ai, se, si, ui, munit_coordinates, fill_missing=np.nan)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.neurons.multi_unit_stack_coordinates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.neurons.multi_match_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correct the color channels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p = Path('data/static22845-18-5-preproc0/data/images/')\n",
    "p = Path(datafile)\n",
    "for filename in tqdm(p.glob('*.npy')):\n",
    "    img = np.load(filename)\n",
    "    if img.shape[0] == 1:\n",
    "        img = np.concatenate((img, 0 * img))\n",
    "        np.save(filename, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Path('data/static22845-18-8-preproc0/data/images/')\n",
    "for filename in tqdm(p.glob('*.npy')):\n",
    "    img = np.load(filename)\n",
    "    if img.shape[0] == 1:\n",
    "        img = np.concatenate((0 *  img, img))\n",
    "        np.save(filename, img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augment with multi-cell matching (don't use this for now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmatch.MatchingParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in (experiment.Scan() & 'animal_id=22564').proj():\n",
    "    filename = (template + '/').format(**key)\n",
    "    dat = FileTreeDataset(filename, 'images', 'responses')\n",
    "    rel = xmatch.UnitMatching.Match() * xmatch.neuro_data.StaticMultiDataset.Member() & key & 'match_params=1'\n",
    "    \n",
    "    ai, se, si, ui, match_id = rel.fetch('animal_id', 'session', 'scan_idx', 'unit_id', 'match_id')\n",
    "    dat.add_neuron_meta('multi_match_id', ai, se, si, ui, match_id, fill_missing=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(dat.neurons.multi_match_id < 0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.change_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lengths of datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in (experiment.Scan() & 'animal_id=22564').proj():\n",
    "    filename = 'data/static{animal_id}-{session}-{scan_idx}-preproc0/'.format(**key)\n",
    "    dat = FileTreeDataset(filename, 'images', 'responses')\n",
    "    print(len(dat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
